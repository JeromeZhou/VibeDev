---
name: cost-optimization
description: "成本优化 — LLM API 成本控制、模型选择、预算管理"
---

# Cost Optimization Skill — 成本优化

## 预算框架
- 月度预算: $80
- 80% ($64): 警告，开始监控
- 90% ($72): 降级模型（glm-4-9b-chat → Qwen2.5-7B）
- 95% ($76): 暂停非关键任务（隐藏需求推导、热词发现）
- 100% ($80): 只保留数据采集（零 LLM 成本）

## 模型成本矩阵（SiliconFlow）

### 免费模型（首选）
| 模型 | 用途 | 质量 |
|------|------|------|
| THUDM/glm-4-9b-chat | L2 分类、痛点提取 | ★★★ |
| Qwen/Qwen2.5-7B-Instruct | 备用、降级 | ★★★ |
| THUDM/glm-z1-9b | 推理任务 | ★★★ |
| deepseek-ai/DeepSeek-R1-Distill-Qwen-7B | 复杂推理 | ★★★★ |

### 付费模型（按需）
| 模型 | 价格（/M token） | 用途 |
|------|------------------|------|
| THUDM/glm-4-plus | $0.5 in/$0.5 out | 高质量推理 |
| Qwen/Qwen2.5-72B-Instruct | $4.13/$4.13 | 复杂分析 |
| glm-5-plus | $0.5/$0.5 | 白天推理任务 |

## 成本优化策略

### 1. 漏斗前置过滤
- L1 本地信号词过滤: 零成本，过滤 60-70% 无关帖子
- L2 批量分类: 25 条/批，比逐条分析节省 80% token
- 效果: 345 条 → 78 条有信号 → 52 条进 L2 → 42 条分析

### 2. 模型混用
- 清洗/分类: 免费模型（glm-4-9b-chat）
- 痛点提取: 免费模型
- 隐藏需求推导: 免费模型（白天可用 glm-5）
- Munger 审查: 免费模型
- 语义去重: 免费模型

### 3. Token 节约
- 帖子内容截断到 2000 字符
- 评论截断到 2000 字符
- 批量 prompt 复用 system message
- 输出格式约束（JSON，减少废话）

### 4. 时间策略
- glm-5/glm-5-plus: 白天使用（晚间超时率高）
- 免费模型: 全天可用
- 高峰期（20:00-24:00）: 只用免费模型

## 成本追踪
- 每次 LLM 调用记录到 `logs/cost.log`
- 字段: timestamp, model, input_tokens, output_tokens, cost_usd
- 月度汇总: 按模型分组统计
- Web UI /admin 页面实时显示

## 每轮成本估算
| 步骤 | Token 消耗 | 成本 |
|------|-----------|------|
| L2 分类（3 批） | ~3000 | $0.00 |
| 痛点提取（42 条） | ~8000 | $0.00 |
| 语义去重 | ~2000 | $0.00 |
| 隐藏需求推导（5 条） | ~5000 | $0.00 |
| Munger 审查（5 条） | ~3000 | $0.00 |
| **合计** | **~21000** | **~$0.00** |

注: 使用免费模型时实际成本为 $0，但仍记录 token 消耗用于监控。

## 异常检测
- 单轮成本 > $0.50: 告警（可能用了付费模型）
- 月度增速 > 20%/周: 告警
- Token 消耗突增 > 3x: 检查是否有无限循环
