#!/usr/bin/env python3
"""
GPU-Insight ä¸»å…¥å£ â€” v2 ä¸‰å±‚æ¼æ–— + GPU æ ‡ç­¾ + PainInsight
"""

import os
import sys
import builtins
import functools
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv

sys.stdout.reconfigure(encoding='utf-8')
# å…¨å±€è¦†ç›– printï¼Œç¡®ä¿æ‰€æœ‰æ¨¡å—éƒ½ flush
builtins.print = functools.partial(builtins.print, flush=True)
load_dotenv(Path(__file__).parent / ".env")

from src.utils.config import load_config
from src.utils.llm_client import LLMClient
from src.utils.cost_tracker import CostTracker
from src.utils.db import init_db


def check_agent_teams_available() -> bool:
    return os.getenv("CLAUDE_CODE_EXPERIMENTAL_AGENT_TEAMS") == "1"


def run_with_agent_teams(config: dict):
    print("å¯åŠ¨ Agent Teams æ¨¡å¼ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰")


def is_lite_mode(config: dict) -> bool:
    """æ£€æµ‹æ˜¯å¦ä¸ºè½»é‡æ¨¡å¼"""
    lm = config.get("lite_mode", {})
    if not lm.get("enabled"):
        return False
    return datetime.now().hour in lm.get("hours", [])


def run_pipeline(config: dict):
    """å®Œæ•´ pipelineï¼šæŠ“å– â†’ æ¸…æ´— â†’ GPUæ ‡ç­¾ â†’ ä¸‰å±‚æ¼æ–— â†’ ç—›ç‚¹æå– â†’ æ¨ç†éœ€æ±‚ â†’ PPHI â†’ æŠ¥å‘Š"""
    # DB åˆå§‹åŒ–ï¼ˆåªåœ¨è¿›ç¨‹é¦–æ¬¡è°ƒç”¨æ—¶æ‰§è¡Œå»ºè¡¨+è¿ç§»ï¼‰
    init_db()

    lite = is_lite_mode(config)
    if lite:
        print("å¯åŠ¨ä¸²è¡Œæ¨¡å¼ [è½»é‡]")
        print(f"  æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}")
        print("  è·³è¿‡ä¸ç¨³å®šæºå’Œé«˜æˆæœ¬ AI æ­¥éª¤")
    else:
        print("å¯åŠ¨ä¸²è¡Œæ¨¡å¼")
        print(f"  æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print()

    llm = LLMClient(config)
    cost_tracker = CostTracker(config)

    # 0. é¢„ç®—æ£€æŸ¥
    budget = cost_tracker.check_budget()
    print(f"[é¢„ç®—] ${budget['monthly_cost']:.2f} / ${budget['budget']} ({budget['status']})")
    if budget["status"] in ("stop", "pause"):
        print("  é¢„ç®—ä¸è¶³ï¼Œæš‚åœè¿è¡Œ")
        return
    print()

    # 1. æŠ“å–
    from src.scrapers import scrape_all_forums
    print("[1] æ•°æ®é‡‡é›†...")
    skip_sources = config.get("lite_mode", {}).get("skip_sources", []) if lite else []
    raw_posts = scrape_all_forums(config, skip_sources=skip_sources)
    print(f"  è·å– {len(raw_posts)} æ¡æ–°è®¨è®º")
    if not raw_posts:
        print("  æœ¬è½®æ— æ–°æ•°æ®ï¼Œé‡æ–°è®¡ç®—å†å²æ’åï¼ˆPPHI æ—¶é—´è¡°å‡ï¼‰")
        print()
        # å³ä½¿æ— æ–°æ•°æ®ï¼Œä¹Ÿé‡æ–°è®¡ç®—æ’åï¼ˆPPHI æœ‰æ—¶é—´è¡°å‡ï¼‰
        try:
            from src.rankers import calculate_pphi
            from src.utils.db import save_rankings, get_post_count
            from src.reporters import generate_report, update_consensus
            rankings = calculate_pphi([], config)
            if rankings:
                save_rankings(rankings)
                report_path = generate_report(rankings, config)
                cost_info = {
                    "round_cost": 0, "round_tokens": 0,
                    "monthly_cost": cost_tracker.get_monthly_cost(),
                    "budget": cost_tracker.budget,
                }
                update_consensus(rankings, cost_info, config)
                print(f"  æ›´æ–° {len(rankings)} ä¸ªæ’åï¼ˆçº¯å†å²æ•°æ®ï¼‰")
        except Exception as e:
            print(f"  [!] å†å²æ’åæ›´æ–°å¤±è´¥: {e}")
        return
    print()

    # 2. æ¸…æ´—
    from src.cleaners import clean_data
    print("[2] æ•°æ®æ¸…æ´—...")
    cleaned = clean_data(raw_posts, config)
    print(f"  å»é‡å {len(cleaned)} æ¡")
    print()

    # 3. GPU äº§å“æ ‡ç­¾ï¼ˆL0 æœ¬åœ°ï¼Œé›¶ tokenï¼‰
    from src.utils.gpu_tagger import tag_posts
    print("[3] GPU äº§å“æ ‡ç­¾...")
    cleaned = tag_posts(cleaned)
    tagged_count = sum(1 for p in cleaned if p.get("_gpu_tags", {}).get("models"))
    print(f"  è¯†åˆ«åˆ°å…·ä½“å‹å·: {tagged_count} æ¡ | è¯†åˆ«åˆ°å“ç‰Œ: {sum(1 for p in cleaned if p.get('_gpu_tags', {}).get('brands'))} æ¡")
    print()

    # 3.5 AI ç›¸å…³æ€§è¿‡æ»¤ï¼ˆåœ¨ GPU tagger ä¹‹åï¼Œåˆ©ç”¨ _gpu_tags å¿«é€Ÿé€šé“ï¼‰
    skip_steps = config.get("lite_mode", {}).get("skip_steps", []) if lite else []
    if "ai_filter" in skip_steps:
        print("[3.5] AI ç›¸å…³æ€§è¿‡æ»¤... è·³è¿‡ï¼ˆè½»é‡æ¨¡å¼ï¼‰")
    else:
        from src.filters import filter_gpu_relevant
        print("[3.5] AI ç›¸å…³æ€§è¿‡æ»¤...")
        pre_count = len(cleaned)
        cleaned = filter_gpu_relevant(cleaned, llm, shadow=False)
        dropped_count = pre_count - len(cleaned)
        # æŒä¹…åŒ– relevance ç»“æœåˆ° DB
        try:
            from src.utils.db import save_posts
            save_posts(cleaned)
        except Exception as e:
            print(f"  [!] ä¿å­˜ relevance ç»“æœå¤±è´¥: {e}")
    print()

    # 4. ä¸‰å±‚æ¼æ–—
    from src.analyzers.funnel import run_funnel
    print("[4] ä¸‰å±‚æ¼æ–—ç­›é€‰...")
    deep_posts, light_posts = run_funnel(cleaned, llm)
    print()

    # 5. ç—›ç‚¹æå–ï¼ˆå¯¹ deep + light åˆ†åˆ«å¤„ç†ï¼‰
    from src.analyzers import analyze_pain_points, infer_hidden_needs, merge_pain_insights
    print(f"[5] ç—›ç‚¹æå–ï¼ˆæ·±åº¦ {len(deep_posts)} + è½»åº¦ {len(light_posts)} æ¡ï¼‰...")
    status = cost_tracker.enforce_budget(llm)
    if status in ("stop", "pause"):
        print("  é¢„ç®—ä¸è¶³ï¼Œè·³è¿‡åç»­æ­¥éª¤")
        return
    all_posts_for_analysis = deep_posts + light_posts
    pain_points = analyze_pain_points(all_posts_for_analysis, config, llm)
    print(f"  æå– {len(pain_points)} ä¸ªç—›ç‚¹")
    print()

    # 6. æ¨ç†éœ€æ±‚ï¼ˆå¯¹æ‰€æœ‰ç—›ç‚¹åšæ¨ç†ï¼Œä¼˜å…ˆ deepï¼Œæ§åˆ¶æ•°é‡ï¼‰
    hidden_needs = []
    if "hidden_needs" in skip_steps:
        print("[6] éšè—éœ€æ±‚æ¨å¯¼... è·³è¿‡ï¼ˆè½»é‡æ¨¡å¼ï¼‰")
    else:
        # ä¼˜å…ˆ deep_posts æ¥æºçš„ç—›ç‚¹ï¼Œä¸è¶³æ—¶è¡¥å…… light_posts æ¥æºçš„
        deep_ids = set(p.get("id") for p in deep_posts)
        deep_pains = [pp for pp in pain_points
                      if any(pid in deep_ids for pid in pp.get("source_post_ids", []))]
        light_pains = [pp for pp in pain_points if pp not in deep_pains]
        # å…¨éƒ¨æ¨å¯¼ï¼ˆdeep ä¼˜å…ˆæ’åºï¼‰
        pains_for_inference = deep_pains + light_pains

        # å›å¡«ï¼šä» DB å†å²ä¸­æ‰¾ç¼ºå°‘ hidden_need çš„é«˜æ’åç—›ç‚¹ï¼Œè¡¥å……æ¨å¯¼
        backfill = []
        try:
            from src.utils.db import get_db
            with get_db() as conn:
                rows = conn.execute(
                    """SELECT pain_point, pphi_score FROM pphi_history
                       WHERE (hidden_need IS NULL OR hidden_need = '')
                       AND run_date = (SELECT MAX(run_date) FROM pphi_history)
                       ORDER BY pphi_score DESC"""
                ).fetchall()
                existing_names = set(p.get("pain_point", "") for p in pains_for_inference)
                for r in rows:
                    if r["pain_point"] not in existing_names:
                        backfill.append({
                            "pain_point": r["pain_point"],
                            "category": "",
                            "emotion_intensity": 0.5,
                            "evidence": "",
                            "source_post_ids": [],
                            "source_urls": [],
                        })
        except Exception:
            pass

        # åˆå¹¶ï¼šå½“è½®å…¨éƒ¨ + å†å²å›å¡«
        if backfill:
            pains_for_inference.extend(backfill)

        # ç»™æ¯ä¸ªç—›ç‚¹åŠ ç´¢å¼•ï¼Œç”¨äºåç»­ merge æ—¶ç²¾ç¡®å…³è”ï¼ˆä¸ä¾èµ– LLM å›æ˜¾æ–‡æœ¬ï¼‰
        for idx, pp in enumerate(pains_for_inference):
            pp["_inference_idx"] = idx
        backfill_count = len(backfill)
        print(f"[6] éšè—éœ€æ±‚æ¨å¯¼ï¼ˆ{len(pains_for_inference)} ä¸ªç—›ç‚¹ï¼š{len(deep_pains)} æ·±åº¦ + {len(light_pains)} è½»åº¦ + {backfill_count} å›å¡«ï¼‰...")
        status = cost_tracker.enforce_budget(llm)
        if status == "pause":
            print("  é¢„ç®—ä¸è¶³ï¼Œè·³è¿‡éšè—éœ€æ±‚æ¨å¯¼")
        elif status == "stop":
            print("  é¢„ç®—ä¸è¶³ï¼Œåœæ­¢è¿è¡Œ")
            return
        else:
            hidden_needs = infer_hidden_needs(pains_for_inference, config, llm)
            print(f"  æ¨å¯¼ {len(hidden_needs)} ä¸ªéšè—éœ€æ±‚")

            # å›å¡«çš„éšè—éœ€æ±‚ç›´æ¥å†™å…¥ DBï¼ˆå®ƒä»¬ä¸åœ¨å½“è½® pain_points ä¸­ï¼‰
            if backfill_count > 0:
                try:
                    from src.utils.db import get_db
                    backfill_names = set(b["pain_point"] for b in backfill)
                    for hn in hidden_needs:
                        orig = hn.get("_original_pain", "") or hn.get("pain_point", "")
                        if orig in backfill_names and hn.get("hidden_need"):
                            with get_db() as conn:
                                conn.execute(
                                    "UPDATE pphi_history SET hidden_need = ? WHERE pain_point = ? AND (hidden_need IS NULL OR hidden_need = '')",
                                    (hn["hidden_need"], orig)
                                )
                            print(f"    å›å¡«: {orig[:25]} â†’ {hn['hidden_need'][:30]}")
                except Exception as e:
                    print(f"    [!] å›å¡«å†™å…¥å¤±è´¥: {e}")
    print()

    # 6.5 Devil's Advocate å®¡æŸ¥ï¼ˆé˜²å¹»è§‰æœºåˆ¶ï¼‰
    from src.analyzers import devils_advocate_review
    if hidden_needs and "munger" not in skip_steps:
        print("[6.5] Devil's Advocate å®¡æŸ¥ï¼ˆMunger åå‘è®ºè¯ï¼‰...")
        status = cost_tracker.enforce_budget(llm)
        if status == "pause":
            print("  é¢„ç®—ä¸è¶³ï¼Œè·³è¿‡ Devil's Advocate å®¡æŸ¥")
        elif status == "stop":
            print("  é¢„ç®—ä¸è¶³ï¼Œåœæ­¢è¿è¡Œ")
            return
        else:
            hidden_needs = devils_advocate_review(hidden_needs, llm)
        print()
    elif "munger" in skip_steps and hidden_needs:
        print("[6.5] Devil's Advocate å®¡æŸ¥... è·³è¿‡ï¼ˆè½»é‡æ¨¡å¼ï¼‰")
        print()

    # 7. åˆå¹¶ä¸º PainInsight
    print("[7] åˆå¹¶ PainInsight...")
    insights = merge_pain_insights(pain_points, hidden_needs)
    print(f"  ç”Ÿæˆ {len(insights)} ä¸ª PainInsight")
    print()

    # 8. PPHI æ’å
    from src.rankers import calculate_pphi
    print("[8] PPHI æ’åè®¡ç®—...")
    rankings = calculate_pphi(insights, config)
    print(f"  ç”Ÿæˆ {len(rankings)} ä¸ªæ’å")

    # æŒä¹…åŒ–ï¼šä¿å­˜æ’åå’Œç—›ç‚¹åˆ° SQLite
    try:
        from src.utils.db import save_rankings, save_pain_points, get_post_count
        save_rankings(rankings)
        save_pain_points(insights)
        stats = get_post_count()
        print(f"  [DB] ç´¯è®¡å¸–å­: {stats['total']} | æ¥æº: {stats['by_source']}")
    except Exception as e:
        print(f"  [!] DB ä¿å­˜å¤±è´¥(ä¸å½±å“è¿è¡Œ): {e}")
    print()

    # 9. ç”ŸæˆæŠ¥å‘Š
    from src.reporters import generate_report
    print("[9] ç”ŸæˆæŠ¥å‘Š...")
    report_path = generate_report(rankings, config)
    print(f"  æŠ¥å‘Šï¼š{report_path}")
    print()

    # 10. æ›´æ–°å…±è¯†
    from src.reporters import update_consensus
    print("[10] æ›´æ–°å…±è¯†...")
    cost_info = {
        "round_cost": llm.total_cost,
        "round_tokens": llm.total_tokens,
        "monthly_cost": cost_tracker.get_monthly_cost(),
        "budget": cost_tracker.budget,
    }
    update_consensus(rankings, cost_info, config)
    print()

    # 10.5 çƒ­è¯è‡ªåŠ¨å‘ç°ï¼ˆä» AI åˆ†æç»“æœ + åŸå§‹å¸–å­ + DB å†å²æ•°æ®ä¸­æå–ï¼‰
    try:
        from src.utils.keywords import discover_hot_words, discover_from_db, update_discovered_keywords
        # ä»å½“è½® AI è¾“å‡º + åŸå§‹å¸–å­æå–
        new_words = discover_hot_words(raw_posts, min_freq=2, insights=insights)
        # ä» DB å†å²æ•°æ®è¡¥å……
        db_words = discover_from_db(min_mentions=2)
        # åˆå¹¶ï¼ˆå»é‡ï¼‰
        merged_zh = list(dict.fromkeys((new_words.get("zh", []) + db_words.get("zh", []))))
        merged_en = list(dict.fromkeys((new_words.get("en", []) + db_words.get("en", []))))
        merged = {"zh": merged_zh, "en": merged_en}
        if merged["zh"] or merged["en"]:
            update_discovered_keywords(merged)
            print(f"[10.5] çƒ­è¯å‘ç°: +{len(merged['zh'])} ä¸­æ–‡, +{len(merged['en'])} è‹±æ–‡")
            if db_words.get("model_ranks"):
                print(f"  å‹å·çƒ­åº¦ Top5: {', '.join(db_words['model_ranks'][:5])}")
            print()
    except Exception as e:
        print(f"  [!] çƒ­è¯å‘ç°å¤±è´¥(ä¸å½±å“è¿è¡Œ): {e}")
        print()

    # 11. è¾“å‡º Top 10
    trend_icons = {"hot": "ğŸ”¥", "rising": "â†‘", "falling": "â†“", "stable": "â†’", "new": "â˜…"}
    print("=" * 70)
    print("  GPU-Insight Top 10 ç—›ç‚¹æ’å")
    print("=" * 70)
    print()
    for r in rankings[:10]:
        gpu = r.get("gpu_tags", {})
        models = ", ".join(gpu.get("models", [])) or "-"
        mfrs = ", ".join(gpu.get("manufacturers", [])) or "-"
        urls = r.get("source_urls", [])
        url_str = urls[0][:60] if urls else "-"
        need = r.get("hidden_need", "")
        trend = trend_icons.get(r.get("trend", "new"), "â˜…")
        print(f"  #{r['rank']:2d} {trend} [PPHI {r['pphi_score']:5.1f}] {r['pain_point']}")
        print(f"       GPU: {models} | å‚å•†: {mfrs}")
        print(f"       æ¥æº: {url_str}")
        if need:
            print(f"       éœ€æ±‚: {need}")
        print()

    # æˆæœ¬
    budget = cost_tracker.check_budget()
    print(f"[æˆæœ¬] æœ¬è½®: ${llm.total_cost:.4f} | Token: {llm.total_tokens} | æœˆåº¦: ${budget['monthly_cost']:.2f} / ${budget['budget']}")

    # LLM é™çº§è¿½è¸ª
    usage = llm.get_usage_summary()
    if usage["fallback_count"] > 0:
        print(f"  [!] LLM é™çº§ {usage['fallback_count']} æ¬¡ | å®é™…æ¨¡å‹: {usage['models_used']}")

    # DB å¤‡ä»½ï¼ˆæ¯è½®ç»“æŸåå¤‡ä»½ï¼Œä¿ç•™æœ€è¿‘ 7 ä»½ï¼‰
    try:
        from src.utils.db import backup_db, cleanup_old_history
        backup_db()
        cleanup_old_history(keep_runs=30)
    except Exception as e:
        print(f"  [!] DB å¤‡ä»½/æ¸…ç†å¤±è´¥: {e}")

    # å‘¨æŠ¥ï¼ˆæ¯å‘¨ä¸€è‡ªåŠ¨ç”Ÿæˆï¼‰
    if datetime.now().weekday() == 0:  # Monday
        try:
            from src.reporters.weekly import generate_weekly_report
            weekly_path = generate_weekly_report(config)
            if weekly_path:
                print(f"[å‘¨æŠ¥] {weekly_path}")
        except Exception as e:
            print(f"  [!] å‘¨æŠ¥ç”Ÿæˆå¤±è´¥: {e}")

    print()
    print("æœ¬è½®å®Œæˆ")


def main():
    print("=" * 50)
    print("  GPU-Insight æ˜¾å¡ç”¨æˆ·ç—›ç‚¹æ™ºèƒ½åˆ†æç³»ç»Ÿ")
    print("=" * 50)
    print()

    try:
        config = load_config("config/config.yaml")
    except FileNotFoundError as e:
        print(f"é”™è¯¯: {e}")
        sys.exit(1)

    # å®šæ—¶æ¨¡å¼ï¼špython main.py --loop
    if "--loop" in sys.argv:
        import time
        interval = config.get("runtime", {}).get("cycle_interval_hours", 4) * 3600
        print(f"å®šæ—¶æ¨¡å¼ï¼šæ¯ {interval/3600:.0f} å°æ—¶è¿è¡Œä¸€è½®")
        print()
        while True:
            try:
                run_pipeline(config)
            except Exception as e:
                print(f"\n[!] Pipeline å¼‚å¸¸: {e}")
            next_run = datetime.now().strftime('%H:%M')
            print(f"\nä¸‹ä¸€è½®: {interval/3600:.0f}h å")
            print("-" * 50)
            time.sleep(interval)
        return

    agent_teams_enabled = config.get("agent_teams", {}).get("enabled", False)
    agent_teams_available = check_agent_teams_available()

    if agent_teams_enabled and agent_teams_available:
        run_with_agent_teams(config)
    else:
        if agent_teams_enabled and not agent_teams_available:
            print("Agent Teams å·²é…ç½®ä½†ä¸å¯ç”¨ï¼Œé™çº§ä¸ºä¸²è¡Œæ¨¡å¼")
            print()
        run_pipeline(config)


if __name__ == "__main__":
    main()
