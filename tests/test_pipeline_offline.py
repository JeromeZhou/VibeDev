"""GPU-Insight ç¦»çº¿ Pipeline æµ‹è¯• â€” ä¸ä¾èµ– LLM APIï¼Œç”¨è§„åˆ™æ¨¡æ‹Ÿåˆ†æ"""

import sys
import json
import re
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° path
sys.path.insert(0, str(Path(__file__).resolve().parent.parent))

from tests.mock_data import generate_mock_data
from src.utils.config import load_config
from src.cleaners import clean_data
from src.rankers import calculate_pphi
from src.reporters import generate_report


# ============================================================
# è§„åˆ™å¼•æ“ï¼šä¸è°ƒç”¨ LLMï¼Œç”¨å…³é”®è¯åŒ¹é…æ¨¡æ‹Ÿç—›ç‚¹æå–å’Œéœ€æ±‚æ¨å¯¼
# ============================================================

PAIN_RULES = [
    {"keywords": ["æ˜¾å­˜", "VRAM", "çˆ†æ˜¾å­˜", "æ˜¾å­˜ä¸å¤Ÿ"], "pain": "æ˜¾å­˜å®¹é‡ä¸è¶³", "category": "æ˜¾å­˜", "intensity": 0.85},
    {"keywords": ["åŠŸè€—", "åŠŸè€—å¢™", "power", "æ•£çƒ­å‹ä¸ä½"], "pain": "åŠŸè€—ä¸æ•£çƒ­å¤±æ§", "category": "åŠŸè€—", "intensity": 0.75},
    {"keywords": ["driver", "é©±åŠ¨", "crash", "TDR", "é»‘å±"], "pain": "é©±åŠ¨ç¨³å®šæ€§å·®", "category": "é©±åŠ¨", "intensity": 0.80},
    {"keywords": ["ä»·æ ¼", "åŠ ä»·", "ä¹°ä¸åˆ°", "ç©ä¸èµ·"], "pain": "æ˜¾å¡ä»·æ ¼è¿‡é«˜", "category": "ä»·æ ¼", "intensity": 0.90},
    {"keywords": ["FSR", "DLSS", "ç”»è´¨", "æ¨¡ç³Š", "é¬¼å½±"], "pain": "AI è¶…åˆ†ç”»è´¨ä¸ä½³", "category": "ç”Ÿæ€", "intensity": 0.65},
    {"keywords": ["çŸ¿å¡", "ç¿»æ–°", "äºŒæ‰‹"], "pain": "äºŒæ‰‹å¸‚åœºä¿¡ä»»å±æœº", "category": "å…¶ä»–", "intensity": 0.60},
    {"keywords": ["4K", "120Hz", "144Hz", "é«˜åˆ·"], "pain": "ä¸­ç«¯å¡æ— æ³•æ»¡è¶³ 4K é«˜åˆ·", "category": "æ€§èƒ½", "intensity": 0.70},
    {"keywords": ["Linux", "Wayland", "å¼€æºé©±åŠ¨"], "pain": "Linux é©±åŠ¨ä½“éªŒå·®", "category": "é©±åŠ¨", "intensity": 0.70},
    {"keywords": ["å™ªéŸ³", "é£æ‰‡", "åˆ†è´", "rpm"], "pain": "æ•£çƒ­å™ªéŸ³è¿‡å¤§", "category": "æ•£çƒ­", "intensity": 0.65},
    {"keywords": ["LLM", "å¤§æ¨¡å‹", "æœ¬åœ°è·‘", "48G", "AI"], "pain": "æ¶ˆè´¹çº§æ˜¾å¡æ— æ³•è¿è¡Œæœ¬åœ°å¤§æ¨¡å‹", "category": "æ˜¾å­˜", "intensity": 0.88},
    {"keywords": ["HDMI", "DP", "æ¥å£", "å¸¦å®½"], "pain": "æ˜¾ç¤ºæ¥å£æ ‡å‡†æ··ä¹±", "category": "ç”Ÿæ€", "intensity": 0.55},
    {"keywords": ["æœºç®±", "æ”¾ä¸ä¸‹", "å¤ªå¤§", "é•¿åº¦"], "pain": "æ˜¾å¡ä½“ç§¯è¿‡å¤§", "category": "æ•£çƒ­", "intensity": 0.60},
]

NEED_MAP = {
    "æ˜¾å­˜å®¹é‡ä¸è¶³": {
        "need": "å¹³ä»·æ˜¾å¡çš„æœ¬åœ° AI ç®—åŠ›å¹³æƒ",
        "chain": ["ç”¨æˆ·éœ€è¦åœ¨æœ¬åœ°è¿è¡Œ AI åº”ç”¨", "å½“å‰ä¸­ç«¯å¡æ˜¾å­˜ä¸è¶³", "ç”¨æˆ·æ— æ³•æ‰¿æ‹…é«˜ç«¯å¡ä»·æ ¼", "éšè—éœ€æ±‚ï¼šå¹³ä»· AI ç®—åŠ›å¹³æƒ"],
        "confidence": 0.82,
    },
    "åŠŸè€—ä¸æ•£çƒ­å¤±æ§": {
        "need": "é«˜æ€§èƒ½ä½åŠŸè€—çš„èŠ¯ç‰‡æ¶æ„",
        "chain": ["åŠŸè€—å¢™é™åˆ¶äº†æ€§èƒ½é‡Šæ”¾", "æ•£çƒ­æ–¹æ¡ˆè·Ÿä¸ä¸ŠåŠŸè€—å¢é•¿", "ç”¨æˆ·å¸Œæœ›å®‰é™é«˜æ•ˆçš„ä½¿ç”¨ä½“éªŒ", "éšè—éœ€æ±‚ï¼šèƒ½æ•ˆæ¯”é©å‘½"],
        "confidence": 0.75,
    },
    "é©±åŠ¨ç¨³å®šæ€§å·®": {
        "need": "å¼€ç®±å³ç”¨çš„ç¨³å®šé©±åŠ¨ä½“éªŒ",
        "chain": ["é©±åŠ¨æ›´æ–°é¢‘ç¹å¼•å…¥ bug", "ç”¨æˆ·è¢«è¿«å›æ»šé©±åŠ¨", "å½±å“å·¥ä½œå’Œæ¸¸æˆä½“éªŒ", "éšè—éœ€æ±‚ï¼šé©±åŠ¨è´¨é‡ > åŠŸèƒ½å †å "],
        "confidence": 0.78,
    },
    "æ˜¾å¡ä»·æ ¼è¿‡é«˜": {
        "need": "åˆç†çš„æ€§ä»·æ¯”å®šä»·ç­–ç•¥",
        "chain": ["æ˜¾å¡ä»·æ ¼é€ä»£ä¸Šæ¶¨", "ä¸­ç«¯å¡ä»·æ ¼æ¥è¿‘ä¸Šä»£é«˜ç«¯", "æ™®é€šç©å®¶è¢«æŒ¤å‡ºå¸‚åœº", "éšè—éœ€æ±‚ï¼šé‡å»ºä¸­ç«¯å¸‚åœºæ€§ä»·æ¯”"],
        "confidence": 0.90,
    },
    "æ¶ˆè´¹çº§æ˜¾å¡æ— æ³•è¿è¡Œæœ¬åœ°å¤§æ¨¡å‹": {
        "need": "æ¶ˆè´¹çº§ AI æ¨ç†ä¸“ç”¨æ˜¾å¡",
        "chain": ["AI åº”ç”¨çˆ†å‘å¼å¢é•¿", "æœ¬åœ°æ¨ç†éœ€è¦å¤§æ˜¾å­˜", "æ¶ˆè´¹çº§æœ€å¤§ 24G è¿œä¸å¤Ÿ", "éšè—éœ€æ±‚ï¼šé¢å‘ AI çš„æ¶ˆè´¹çº§äº§å“çº¿"],
        "confidence": 0.85,
    },
}


def rule_based_extract(posts: list[dict]) -> list[dict]:
    """åŸºäºè§„åˆ™çš„ç—›ç‚¹æå–"""
    results = []
    for post in posts:
        text = (post.get("title", "") + " " + post.get("content", "")).lower()
        for rule in PAIN_RULES:
            if any(kw.lower() in text for kw in rule["keywords"]):
                results.append({
                    "pain_point": rule["pain"],
                    "category": rule["category"],
                    "emotion_intensity": rule["intensity"],
                    "summary": post.get("title", ""),
                    "_source": post.get("_source", post.get("source", "unknown")),
                    "_post_id": post.get("id", ""),
                })
                break  # æ¯æ¡è®¨è®ºåªåŒ¹é…ç¬¬ä¸€ä¸ªè§„åˆ™
    return results


def rule_based_infer(pain_points: list[dict]) -> list[dict]:
    """åŸºäºè§„åˆ™çš„éšè—éœ€æ±‚æ¨å¯¼"""
    results = []
    seen = set()
    for pp in pain_points:
        pain = pp["pain_point"]
        if pain in seen:
            continue
        seen.add(pain)
        mapping = NEED_MAP.get(pain)
        if mapping:
            results.append({
                "pain_point": pain,
                "hidden_need": mapping["need"],
                "reasoning_chain": mapping["chain"],
                "confidence": mapping["confidence"],
                "approved": True,
                "adjusted_confidence": mapping["confidence"] * 0.9,
                "_source": pp.get("_source", "unknown"),
            })
        else:
            results.append({
                "pain_point": pain,
                "hidden_need": f"éœ€è¦è¿›ä¸€æ­¥åˆ†æ: {pain}",
                "reasoning_chain": ["è§„åˆ™åº“æœªè¦†ç›–", "éœ€è¦ LLM æ·±åº¦åˆ†æ"],
                "confidence": 0.4,
                "approved": False,
                "adjusted_confidence": 0.3,
                "_source": pp.get("_source", "unknown"),
            })
    return results


def main():
    print("=" * 55)
    print("  GPU-Insight Pipeline æµ‹è¯•ï¼ˆç¦»çº¿æ¨¡å¼ / è§„åˆ™å¼•æ“ï¼‰")
    print("=" * 55)
    print()

    # åŠ è½½é…ç½®
    config = load_config("config/config.yaml")

    # 1. ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®
    print("ğŸ“¥ [é˜¶æ®µ1] ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®...")
    raw_posts = generate_mock_data()
    print(f"   ç”Ÿæˆ {len(raw_posts)} æ¡è®¨è®º")
    print()

    # 2. æ¸…æ´—
    print("ğŸ§¹ [é˜¶æ®µ2] æ•°æ®æ¸…æ´—...")
    cleaned = clean_data(raw_posts, config)
    print(f"   å»é‡åå‰©ä½™ {len(cleaned)} æ¡")
    print()

    # 3. ç—›ç‚¹æå–ï¼ˆè§„åˆ™å¼•æ“ï¼‰
    print("ğŸ” [é˜¶æ®µ3] ç—›ç‚¹æå–ï¼ˆè§„åˆ™å¼•æ“ï¼‰...")
    pain_points = rule_based_extract(cleaned)
    print(f"   æå– {len(pain_points)} ä¸ªç—›ç‚¹")
    for pp in pain_points:
        print(f"     [{pp['category']}] {pp['pain_point']} (å¼ºåº¦: {pp['emotion_intensity']})")
    print()

    # 4. éšè—éœ€æ±‚æ¨å¯¼ï¼ˆè§„åˆ™å¼•æ“ï¼‰
    print("ğŸ’¡ [é˜¶æ®µ4] éšè—éœ€æ±‚æ¨å¯¼ï¼ˆè§„åˆ™å¼•æ“ï¼‰...")
    insights = rule_based_infer(pain_points)
    approved = [i for i in insights if i.get("approved")]
    print(f"   æ¨å¯¼ {len(insights)} ä¸ªéœ€æ±‚ï¼Œé€šè¿‡ {len(approved)} ä¸ª")
    for ins in insights:
        status = "âœ…" if ins["approved"] else "âŒ"
        print(f"     {status} {ins['pain_point']} â†’ {ins['hidden_need']} ({ins['confidence']:.0%})")
    print()

    # 5. PPHI æ’å
    print("ğŸ“Š [é˜¶æ®µ5] PPHI æ’åè®¡ç®—...")
    rankings = calculate_pphi(approved, config)
    print(f"   ç”Ÿæˆ {len(rankings)} ä¸ªæ’å")
    for r in rankings[:10]:
        print(f"     #{r['rank']} {r['pain_point']} â€” PPHI: {r['pphi_score']}")
    print()

    # 6. ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“ [é˜¶æ®µ6] ç”ŸæˆæŠ¥å‘Š...")
    report_path = generate_report(rankings, config)
    print(f"   æŠ¥å‘Šï¼š{report_path}")
    print()

    print("âœ… Pipeline æµ‹è¯•å®Œæˆï¼")
    print()

    # è¾“å‡ºç»Ÿè®¡
    print("ğŸ“Š ç»Ÿè®¡æ‘˜è¦ï¼š")
    print(f"   åŸå§‹æ•°æ®ï¼š{len(raw_posts)} æ¡")
    print(f"   æ¸…æ´—åï¼š{len(cleaned)} æ¡")
    print(f"   ç—›ç‚¹ï¼š{len(pain_points)} ä¸ª")
    print(f"   éšè—éœ€æ±‚ï¼ˆé€šè¿‡ï¼‰ï¼š{len(approved)} ä¸ª")
    print(f"   PPHI æ’åï¼š{len(rankings)} ä¸ª")


if __name__ == "__main__":
    main()
